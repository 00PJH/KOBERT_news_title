{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "model = AutoModel.from_pretrained(\"klue/bert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'love', 'Paris']\n"
     ]
    }
   ],
   "source": [
    "sentence = 'I love Paris'\n",
    "token = tokenizer.tokenize(sentence)\n",
    "print(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '[CLS]', 'I', 'love', 'Paris', '[SEP]', '[SEP]']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]', '[CLS]', 'I', 'love', 'Paris', '[SEP]', '[SEP]', '[PAD]', '[PAD]']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = ['[CLS]'] + token + ['[SEP]']\n",
    "print(token)\n",
    "token = token + ['[PAD]'] + ['[PAD]']\n",
    "token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = [1 if i!='[PAD]' else 0 for i in token]\n",
    "attention_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 45, 27415, 27417, 3, 3, 0, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_ids = tokenizer.convert_tokens_to_ids(token)\n",
    "token_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.tensor(token_ids).unsqueeze(0)\n",
    "attention_mask = torch.tensor(attention_mask).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m hidden_rep, cls_head \u001b[38;5;241m=\u001b[39m model(token_ids, attention_mask \u001b[38;5;241m=\u001b[39m attention_mask)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhidden_rep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "hidden_rep, cls_head = model(token_ids, attention_mask = attention_mask)\n",
    "print(hidden_rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df_military_titles = pd.read_csv('news_titles_label1.csv')\n",
    "df_bigkinds_titles = pd.read_csv('bigkinds_news_titles_6066_label0.csv')\n",
    "\n",
    "max_title_len = 128\n",
    "\n",
    "# df_military_titles\n",
    "# 1. 가장 긴 문장 길이: 76\n",
    "# 2. 64~128 길이의 문장 개수: 8\n",
    "# 3. 128~256 길이의 문장 개수: 0\n",
    "\n",
    "#df_bigkinds_titles\n",
    "# 1. 가장 긴 문장 길이: 127\n",
    "# 2. 64~128 길이의 문장 개수: 21\n",
    "# 3. 128~256 길이의 문장 개수: 0\n",
    "\n",
    "\n",
    "# df_bigkinds_titles['title_length'] = df_bigkinds_titles['title'].apply(len)\n",
    "\n",
    "# # 1. 가장 긴 문장 길이\n",
    "# max_length = df_bigkinds_titles['title_length'].max()\n",
    "\n",
    "# # 2. 64~128 길이의 문장 개수\n",
    "# count_64_128 = df_bigkinds_titles[(df_bigkinds_titles['title_length'] >= 64) & (df_bigkinds_titles['title_length'] < 128)].shape[0]\n",
    "\n",
    "# # 3. 128~256 길이의 문장 개수\n",
    "# count_128_256 = df_bigkinds_titles[(df_bigkinds_titles['title_length'] >= 128) & (df_bigkinds_titles['title_length'] < 256)].shape[0]\n",
    "\n",
    "# # 결과 출력\n",
    "# print(f\"1. 가장 긴 문장 길이: {max_length}\")\n",
    "# print(f\"2. 64~128 길이의 문장 개수: {count_64_128}\")\n",
    "# print(f\"3. 128~256 길이의 문장 개수: {count_128_256}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KOBERT_news_title",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
